train_gpu_ids: "0,1"
vllm_gpu_ids: ""

vllm_server:
  host: "vllm-server"
  port: 8000
  group_port: 51216
  tensor_parallel_size: 1
  gpu_memory_utilization: 0.9
